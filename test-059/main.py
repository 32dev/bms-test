from mido import MidiFile
from pydub import AudioSegment
import os
import re

# === ì„¤ì • ===
midi_files = ["input1.mid", "input2.mid", "input3.mid"]
wav_files = ["input1.wav", "input2.wav", "input3.wav"]
output_dir = "notes"
bms_path = "output.bms"
bpm_default = 120
division = 48       # í•œ ë§ˆë”” ë¶„í•  ìˆ˜
base_lane = 11      # ë°±ê·¸ë¼ìš´ë“œ ë ˆì¸ ì‹œì‘

os.makedirs(output_dir, exist_ok=True)

# --- BMS ì´ˆê¸°í™” ---
if not os.path.exists(bms_path):
    print("âš™ï¸ output.bms ì—†ìŒ â†’ ìƒˆë¡œ ìƒì„±")
    header = [
        "*---------------------- HEADER FIELD",
        "#PLAYER 1",
        "#GENRE AUTO_MERGE",
        "#TITLE COMBINED MIDI",
        "#ARTIST AI",
        f"#BPM {bpm_default}",
        "#PLAYLEVEL 1",
        "#RANK 2",
        "#LNTYPE 0",  # LN ì‚¬ìš© ì•ˆí•¨
        "*---------------------- MAIN DATA FIELD"
    ]
    with open(bms_path, "w", encoding="utf-8") as f:
        f.write("\n".join(header))
else:
    print("ğŸ“„ ê¸°ì¡´ output.bms ì¡´ì¬ â†’ ë³‘í•©")

# --- ê¸°ì¡´ BMS ì½ê¸° ---
with open(bms_path, "r", encoding="utf-8") as f:
    bms_lines = f.read().splitlines()

# ê¸°ì¡´ WAV ìµœëŒ€ ì¸ë±ìŠ¤
wav_ids = [int(m.group(1)) for line in bms_lines if (m := re.match(r"#WAV(\d{2})", line))]
next_wav_index = (max(wav_ids) + 1) if wav_ids else 1
print(f"ğŸ§ WAV ì‹œì‘ ì¸ë±ìŠ¤: {next_wav_index:02}")

# ê¸°ì¡´ measure_data ì´ˆê¸°í™”
measure_data = {}
for line in bms_lines:
    m = re.match(r"#(\d{3})(\d{2}):(.*)", line)
    if m:
        measure = int(m.group(1))
        channel = m.group(2)
        data = list(re.findall("..", m.group(3)))
        measure_data.setdefault(measure, {})[channel] = data

# --- MIDI + WAV ë³‘í•© ---
for idx, (midi_path, wav_path) in enumerate(zip(midi_files, wav_files)):
    if not os.path.exists(midi_path) or not os.path.exists(wav_path):
        print(f"âš ï¸ {midi_path} ë˜ëŠ” {wav_path} ì—†ìŒ â†’ ê±´ë„ˆëœ€")
        continue

    lane_channel = f"{base_lane + idx:02}"  # ex: 11,12,13
    print(f"\nğŸ¼ {midi_path} â†’ ì±„ë„ {lane_channel} ë³‘í•© ì¤‘...")

    mid = MidiFile(midi_path)
    ticks_per_beat = mid.ticks_per_beat
    tick_to_sec = lambda t: (t / ticks_per_beat) * (60 / bpm_default)
    audio = AudioSegment.from_file(wav_path)

    # --- MIDI note ì¶”ì¶œ ---
    notes = []
    for track in mid.tracks:
        current_tick = 0
        active_notes = {}
        for msg in track:
            current_tick += msg.time
            if msg.type == "note_on" and msg.velocity > 0:
                active_notes[msg.note] = current_tick
            elif (msg.type == "note_on" and msg.velocity == 0) or msg.type == "note_off":
                if msg.note in active_notes:
                    start_tick = active_notes[msg.note]
                    end_tick = current_tick
                    notes.append((tick_to_sec(start_tick), tick_to_sec(end_tick), msg.note))
                    del active_notes[msg.note]

    notes.sort(key=lambda x: x[0])
    print(f"ğŸ¹ ë…¸íŠ¸ {len(notes)}ê°œ ê°ì§€")

    # --- WAV ì¶”ì¶œ ë° ì¤‘ë³µ ë°©ì§€ ---
    note_map = {}  # (note, ê¸¸ì´) -> WAV ë²ˆí˜¸
    event_list = []

    for start_sec, end_sec, note in notes:
        start_ms = int(start_sec * 1000)
        end_ms = int(end_sec * 1000)
        length_ms = end_ms - start_ms

        key = (note, length_ms)
        if key not in note_map:
            filename = os.path.join(output_dir, f"note_{next_wav_index:02}.wav")
            segment = audio[start_ms:end_ms]
            segment.export(filename, format="wav")
            note_map[key] = next_wav_index
            next_wav_index += 1

        event_list.append((start_sec, end_sec, note_map[key]))

    # --- WAV ë“±ë¡ ---
    insert_index = next((i for i, l in enumerate(bms_lines) if l.startswith("*---------------------- MAIN DATA FIELD")), len(bms_lines))
    for (note, length), idxnum in sorted(note_map.items(), key=lambda x: x[1]):
        bms_lines.insert(insert_index, f"#WAV{idxnum:02} {os.path.basename(output_dir)}/note_{idxnum:02}.wav")

    # --- ë§ˆë””ë³„ ë°°ì¹˜ ---
    bar_duration = (60 / bpm_default) * 4

    for start_sec, end_sec, wav_id in event_list:
        start_measure = int(start_sec // bar_duration)
        end_measure = int(end_sec // bar_duration)
        start_div = int((start_sec % bar_duration) / bar_duration * division)
        end_div = int((end_sec % bar_duration) / bar_duration * division)

        measure_counter = start_measure
        pos_counter = start_div

        while (measure_counter < end_measure) or (measure_counter == end_measure and pos_counter <= end_div):
            if measure_counter not in measure_data:
                measure_data[measure_counter] = {}
            if lane_channel not in measure_data[measure_counter]:
                measure_data[measure_counter][lane_channel] = ["00"] * division

            measure_data[measure_counter][lane_channel][pos_counter] = f"{wav_id:02}"

            pos_counter += 1
            if pos_counter >= division:
                pos_counter = 0
                measure_counter += 1

    print(f"âœ… {midi_path} ì™„ë£Œ (ì±„ë„ {lane_channel}, WAV {len(note_map)}ê°œ)")

# --- MAIN DATA ì¬êµ¬ì„± ---
main_data = ["*---------------------- MAIN DATA FIELD"]
for measure in sorted(measure_data.keys()):
    for channel in sorted(measure_data[measure].keys()):
        data = "".join(measure_data[measure][channel])
        main_data.append(f"#{measure:03}{channel}:{data}")

# --- BMS ì €ì¥ ---
with open(bms_path, "w", encoding="utf-8") as f:
    for line in bms_lines:
        if not line.startswith("#") or not re.match(r"#\d{3}\d{2}:", line):
            f.write(line + "\n")
    f.write("\n".join(main_data))

print("\nğŸ‰ ëª¨ë“  MIDI ë³‘í•© ì™„ë£Œ (MIDI ê¸¸ì´ ê¸°ì¤€, WAV ë¶„í•  ë°°ì¹˜)")
print(f"ğŸ“„ ìµœì¢… BMS: {bms_path}")
