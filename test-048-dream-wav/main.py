from mido import MidiFile
from pydub import AudioSegment
import os

# === ì„¤ì • ===
midi_path = "input.mid"
wav_path = "input.wav"
output_dir = "notes"
bms_path = "output.bms"
bpm_default = 120
division = 16  # ë§ˆë”” ë‚´ ë¶„í•  ìˆ˜

os.makedirs(output_dir, exist_ok=True)

# --- MIDI ì½ê¸° ---
mid = MidiFile(midi_path)
ticks_per_beat = mid.ticks_per_beat
tick_to_sec = lambda t: (t / ticks_per_beat) * (60 / bpm_default)

# --- ì›ë³¸ ì˜¤ë””ì˜¤ ì½ê¸° ---
audio = AudioSegment.from_file(wav_path)

# --- ë…¸íŠ¸ êµ¬ê°„ ê³„ì‚° ---
notes = []  # [(start_sec, end_sec, note)]
for track in mid.tracks:
    current_tick = 0
    active_notes = {}  # {note: start_tick}

    for msg in track:
        current_tick += msg.time

        # ë…¸íŠ¸ ON
        if msg.type == "note_on" and msg.velocity > 0:
            active_notes[msg.note] = current_tick

        # ë…¸íŠ¸ OFF (velocity 0 or note_off)
        elif (msg.type == "note_on" and msg.velocity == 0) or msg.type == "note_off":
            if msg.note in active_notes:
                start_tick = active_notes[msg.note]
                end_tick = current_tick
                if end_tick > start_tick:  # ìœ íš¨ ê¸¸ì´ë§Œ
                    notes.append((tick_to_sec(start_tick), tick_to_sec(end_tick), msg.note))
                del active_notes[msg.note]

# --- êµ¬ê°„ë³„ ì˜¤ë””ì˜¤ ìë¥´ê¸° ---
notes.sort(key=lambda x: x[0])  # ì‹œì‘ì‹œê°„ ìˆœ ì •ë ¬
note_map = {}
wav_index = 1

for start_sec, end_sec, note in notes:
    start_ms = int(start_sec * 1000)
    end_ms = int(end_sec * 1000)
    if end_ms - start_ms < 10:  # ë„ˆë¬´ ì§§ì€ ë…¸íŠ¸ëŠ” ë¬´ì‹œ
        continue

    filename = os.path.join(output_dir, f"note_{wav_index:02}.wav")
    segment = audio[start_ms:end_ms]
    segment.export(filename, format="wav")
    note_map[(start_sec, note)] = wav_index
    wav_index += 1

print(f"ğŸ”Š {wav_index-1}ê°œì˜ ë…¸íŠ¸ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì™„ë£Œ!")

# --- BMS í—¤ë” ì‘ì„± ---
header = [
    "*---------------------- HEADER FIELD",
    "#PLAYER 1",
    "#GENRE MIDI_EXPORT",
    f"#TITLE {os.path.basename(midi_path)}",
    "#ARTIST AI",
    f"#BPM {bpm_default}",
    "#PLAYLEVEL 1",
    "#RANK 2",
    "#LNTYPE 1"
]

for idx in range(1, wav_index):
    header.append(f"#WAV{idx:02} {os.path.basename(output_dir)}/note_{idx:02}.wav")

# --- BMS ì±„ë³´ ì‘ì„± ---
events = sorted(note_map.items(), key=lambda x: x[0][0])
total_duration = notes[-1][1] if notes else 0.0
bar_duration = (60 / bpm_default) * 4
num_measures = int(total_duration // bar_duration) + 1

main_data = ["*---------------------- MAIN DATA FIELD"]

for measure in range(num_measures):
    start = measure * bar_duration
    end = (measure + 1) * bar_duration
    measure_notes = [e for e in events if start <= e[0][0] < end]

    if not measure_notes:
        continue

    note_values = ["00"] * division
    for (sec, note), idx in measure_notes:
        pos = int(((sec - start) / bar_duration) * division)
        pos = min(pos, division - 1)
        if note_values[pos] == "00":
            note_values[pos] = f"{idx:02}"
        else:
            note_values[pos] += f"{idx:02}"

    main_data.append(f"#{measure:03}01:" + "".join(note_values))

# --- ì €ì¥ ---
with open(bms_path, "w", encoding="utf-8") as f:
    f.write("\n".join(header + main_data))

print("âœ… MIDI â†’ WAV â†’ BMS ë³€í™˜ ì™„ë£Œ!")
print(f"ğŸ“ ë…¸íŠ¸ WAV í´ë”: {output_dir}")
print(f"ğŸ“„ BMS íŒŒì¼: {bms_path}")
