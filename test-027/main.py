from pydub import AudioSegment
from mido import MidiFile, tick2second
import os, math

# === ê¸°ë³¸ ì„¤ì • ===
midi = MidiFile("song.mid")
audio = AudioSegment.from_file("song.wav")

ticks_per_beat = midi.ticks_per_beat
tempo = 500000  # ê¸°ë³¸ í…œí¬ (120BPM)
bpm = 120
note_segments = {}

# === ì¶œë ¥ í´ë” ===
os.makedirs("notes", exist_ok=True)

# === MIDI ë¶„ì„ ===
for track in midi.tracks:
    current_time = 0
    for msg in track:
        current_time += msg.time
        if msg.type == "set_tempo":
            tempo = msg.tempo
        elif msg.type == "note_on" and msg.velocity > 0:
            start_time = tick2second(current_time, ticks_per_beat, tempo)
            note_segments.setdefault(msg.note, []).append({"start": start_time})
        elif msg.type in ["note_off", "note_on"] and msg.velocity == 0:
            end_time = tick2second(current_time, ticks_per_beat, tempo)
            if msg.note in note_segments and note_segments[msg.note]:
                if "end" not in note_segments[msg.note][-1]:
                    note_segments[msg.note][-1]["end"] = end_time

# === ì‚¬ìš´ë“œ ìë¥´ê¸° ===
for i, (note, segs) in enumerate(note_segments.items(), start=1):
    for j, seg in enumerate(segs, start=1):
        if "end" not in seg:
            continue
        start_ms = seg["start"] * 1000
        end_ms = seg["end"] * 1000
        if end_ms > start_ms:
            clip = audio[start_ms:end_ms]
            filename = f"notes/note_{i:02}_{j:03}.wav"
            clip.export(filename, format="wav")
            seg["file"] = filename

# === í•´ìƒë„ ì„¸ë°€ ì¡°ì • ===
resolution = 20000  # ë°•ì ì„¸ë¶„í™”

def sec_to_bms_pos(sec):
    beat = (sec * bpm) / 60
    return int(beat * resolution)

# === ì „ì²´ ë…¸íŠ¸ ë¦¬ìŠ¤íŠ¸ ì •ë ¬ ===
all_notes = []
for note, segs in note_segments.items():
    for seg in segs:
        if "end" in seg and "file" in seg:
            all_notes.append({
                "note": note,
                "start": sec_to_bms_pos(seg["start"]),
                "file": seg["file"]
            })

all_notes.sort(key=lambda n: n["start"])

# === BMS í—¤ë” ===
bms = []
bms.append("*---------------------- HEADER FIELD")
bms.append("#PLAYER 1")
bms.append("#GENRE MIDI_EXPORT")
bms.append("#TITLE song_export")
bms.append("#ARTIST AI_GENERATED")
bms.append(f"#BPM {bpm}")
bms.append("#PLAYLEVEL 1")
bms.append("#RANK 3")
bms.append("#LNTYPE 1\n")

# === WAV ë§¤í•‘ ===
unique_files = []
for n in all_notes:
    if n["file"] not in unique_files:
        unique_files.append(n["file"])

for i, fpath in enumerate(unique_files, start=1):
    wid = f"{i:02}"
    name = os.path.basename(fpath)
    bms.append(f"#WAV{wid} {name}")

# === ë…¸íŠ¸ ë°°ì¹˜ ===
bms.append("\n*---------------------- MAIN DATA FIELD")
measure_notes = {}

for n in all_notes:
    measure = n["start"] // (resolution * 4)
    position = (n["start"] % (resolution * 4)) / (resolution * 4)
    key = f"{measure:03}"
    wav_index = unique_files.index(n["file"]) + 1
    lane_id = (n["note"] % 4) + 1  # 4í‚¤ ê¸°ì¤€

    measure_notes.setdefault((key, lane_id), []).append((position, f"{wav_index:02}"))

for (measure, lane), notes in sorted(measure_notes.items()):
    notes.sort(key=lambda x: x[0])
    total = len(notes)
    seq = "".join([wid for _, wid in notes])
    bms.append(f"#{measure}{10+lane}:{seq}")

# === ì €ì¥ ===
with open("output.bms", "w", encoding="utf-8") as f:
    f.write("\n".join(bms))

print("âœ… ë³€í™˜ ì™„ë£Œ: output.bms ìƒì„±")
print("ğŸ§ ì˜ë¦° ë…¸íŠ¸ WAV: ./notes í´ë”ì— ì €ì¥ë¨")
